# -*- coding: utf-8 -*-
"""Copy of Copy of RNNkeras2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1in8ntW5NcywE1EnAM-ReF4skLk0jQlvl
"""

from keras.layers import SimpleRNN
from keras.datasets import imdb
from keras.preprocessing import sequence
max_features = 1000
maxlen = 100
batch_size = 8
print('Loading data...')
(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features)

print(len(input_train), 'train sequences')
input1=input_train[1]

print(input_train.shape, 'test sequences')

input_train = sequence.pad_sequences(input_train, maxlen=maxlen)
input_test = sequence.pad_sequences(input_test, maxlen=maxlen)
print('input_train shape:', input_train.shape)
print('input_test shape:', input_test.shape)

#input_train[1]

from keras.layers import Dense
from keras.models import Sequential
from keras.layers import Embedding, SimpleRNN
model = Sequential()
model.add(Embedding(1000, 2, input_length=100))
model.add(SimpleRNN(20,activation='tanh', use_bias=False))
model.add(Dense(1, activation='sigmoid')) 
model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])
model.summary()
history = model.fit(input_train, y_train,
                     epochs=5,
                     batch_size=100,
                     validation_split=0.2)

testing = model.evaluate(input_test, y_test,batch_size=100, verbose=1)
print(testing)

import matplotlib.pyplot as plt
acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(acc) + 1)
plt.plot(epochs, acc, 'bo', label='Training ACC')
plt.plot(epochs, val_acc, 'b', label='Validation ACC')
plt.title('Training and Validation Accuracy')
#Text(0.5,1,'Training and Validation Accuracy')
plt.legend()
plt.figure()
plt.plot(epochs, loss, 'bo', label='Training Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

for index, layer in enumerate(model.layers):
  #if(isinstance(layer,Conv2D) or isinstance(layer,Dense) or isinstance(layer,MaxPooling2D) or isinstance(layer,BatchNormalization)):
  print(index, (layer.name))

embedding=model.layers[0].get_weights()[0]
embedding.shape

"""RNN=model.layers[1].get_weights()[0]
print(RNN)
print("1")
RNN=model.layers[1].get_weights()[1]
print(RNN)
print("2")
dense =model.layers[2].get_weights()[0]
print(dense)"""

model.save('RNN1.h5')

#PRINT FIRST 1000 Inputs
import numpy as np
import sys
np.set_printoptions(precision=3)
np.set_printoptions(suppress=True)
np.set_printoptions(threshold=sys.maxsize)
a=input_test[0:1000,]

#PRINT WEIGHTS
fileName =model.layers[1].name
fileName = "ih.txt" 
fileHandler = open(fileName, "w")
embed=model.layers[2].get_weights()[0]
flat= embed.flatten()
#print(flat)
#print(flat.shape)
#print(flat[0])
for i in range (20):
  print(flat[i])
  fileHandler.write(str(flat[i]) + "\n")

fileName =model.layers[1].name
fileName = "ih.txt" 
fileHandler = open(fileName, "w")
embed=model.layers[2].get_weights()[1]
flat= embed.flatten()
#print(flat)
#print(flat.shape)
#print(flat[0])
for i in range (1):
  #print(flat[i])
  fileHandler.write(str(flat[i]) + "\n")

model.layers[1].get_weights()[1].shape



#flat[0:100]

#embed

ans=model.predict(input_train[3:4,])
ans

input_train[1].shape

input_train[3:4,]

from keras.layers import Input 
from keras.models import Sequential
from keras.layers import Embedding, SimpleRNN
layer1= Input(shape=(100,))
layer2= Embedding(1000, 2, input_length=100)(layer1)
layer3= (SimpleRNN(20,activation='tanh', use_bias=False))(layer2)
layer4= (Dense(1, activation='sigmoid'))(layer3)

from keras.models import Model
modelTrun = Model(inputs=layer1, outputs=layer2)

modelTrun.summary()

#model.layers[2].get_weights()[0]==modelTrun.layers[3].get_weights()[0]

model.layers[2].get_weights()[1]

modelTrun.layers[1].set_weights(model.layers[0].get_weights())
#modelTrun.layers[2].set_weights(model.layers[1].get_weights())
#modelTrun.layers[3].set_weights(model.layers[2].get_weights())
print(modelTrun.layers[1].name)
#print(modelTrun.layers[2].name)
#print(modelTrun.layers[3].name)

input_train[3:4,]

op=modelTrun.predict(input_train[3:4,])

op.flatten()

ip=input_train[1]



ip_final=input_train[1].reshape(1,20)

import numpy as np
np.savetxt('input1.txt', [ip], delimiter=',', fmt='%d')

ip_final

input_train[1][0]

